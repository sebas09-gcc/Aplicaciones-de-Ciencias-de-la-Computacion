{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XFgl_WT_msoB"
   },
   "source": [
    "# Aplicaciones de Ciencias de la Computación (INF265)\n",
    "## Laboratorio 1: Agente aspirador de 6 posiciones\n",
    "\n",
    "Al finalizar el presente laboratorio se debe tener implementado el entorno de trabajo del agente aspirador de 6 posiciones y un programa reflexivo simple para dicho agente. Las posiciones del entorno son denotadas como loc_A, loc_B, loc_C, loc_D, loc_E y loc_F. Cada una de estas posiciones puede tener el estado 'Dirty' o 'Clean'.  \n",
    "Al final del notebook deberas responder a las preguntas planteadas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZLu9fqhim_KE"
   },
   "source": [
    "# Clase <b>Thing</b>\n",
    "\n",
    "Esta clase generica representa cualquier objeto fisico que puede aparecer en un <b>Ambiente</b>. (No editar)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "FkfexJt4nEUU"
   },
   "outputs": [],
   "source": [
    "class Thing(object):\n",
    "\n",
    "    def is_alive(self):\n",
    "        \"\"\"Cosas 'vivas'deben retornar true.\"\"\"\n",
    "        return hasattr(self, 'alive') and self.alive\n",
    "\n",
    "    def show_state(self):\n",
    "        \"\"\"Muestra el estado interno del agente. Subclases deben sobreescribir esto.\"\"\"\n",
    "        print(\"I don't know how to show_state.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s8cWKKzLnGtD"
   },
   "source": [
    "# Clase <b>Agent</b>\n",
    "\n",
    "Un agente es una subclase de Thing con un slot obligatorio: <b>.program</b>, el cual almacena la funcion que implementa el <b>programa del agente</b>. Esta funcion debe tomar como argumento la <b>percepcion</b> del agente y debe retornar una <b>accion</b>. La definicion de Percepcion y Accion depende del ambiente de trabajo (environment) donde el agente existe. El agente tambien puede tener el slot <b>.performance</b>, que mide el desempeño del agente en su ambiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "adL1GxO4nIOg"
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import random\n",
    "\n",
    "class Agent(Thing):\n",
    "\n",
    "    def __init__(self, program=None):\n",
    "        self.alive = True\n",
    "        self.performance = 0\n",
    "        assert isinstance(program, collections.Callable)\n",
    "        self.program = program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n4TAAIxHnJte"
   },
   "source": [
    "# Clase <b>Environment</b>\n",
    "\n",
    "Esta clase abstracta representa un entorno de tareas. Clases de entornos reales heredan de esta. En un entorno tipicamente se necesitará implementar 2 cosas:\n",
    "<b>percept</b>, que define la percepción que el agente ve; y \n",
    "<b>execute_action</b>, que define los efectos de ejecutar una acción. \n",
    "El entorno mantiene una lista de .things y .agents (el cual es un subconjunto de .things). Cada elemento de .things tiene un slot .location. (No editar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "C9uzpUSMnLjK"
   },
   "outputs": [],
   "source": [
    "class Environment(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.things = []\n",
    "        self.agents = []\n",
    "\n",
    "    def thing_classes(self):\n",
    "        return []  # List of classes that can go into environment\n",
    "\n",
    "    def percept(self, agent):\n",
    "        \"\"\"Retorna la percepción que el agente 'agent' ve en este punto.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def execute_action(self, agent, action):\n",
    "        \"\"\"El agente 'agent' ejecuta una acción 'action' en el entorno.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def default_location(self, thing):\n",
    "        \"\"\"Localización por defecto para colocar una nueva cosa sin localización especificada.\"\"\"\n",
    "        return None\n",
    "\n",
    "    def is_done(self):\n",
    "        \"\"\"Retorna True si no hay ningón agente vivo\"\"\"\n",
    "        return not any(agent.is_alive() for agent in self.agents)\n",
    "\n",
    "    def add_thing(self, thing, location=None):\n",
    "        \"\"\"Añade una cosa thing al entorno en la localización location. \n",
    "           Si thing es un programa de agente, crea un nuevo agente con ese programa.\"\"\"\n",
    "        if not isinstance(thing, Thing):\n",
    "            thing = Agent(thing)\n",
    "        assert thing not in self.things, \"No añade la misma cosa dos veces\"\n",
    "        thing.location = location if location is not None else self.default_location(thing)\n",
    "        self.things.append(thing)\n",
    "        if isinstance(thing, Agent):\n",
    "            thing.performance = 0\n",
    "            self.agents.append(thing)\n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"Ejecuta un paso del entorno (llama a los programas de los agentes, obtiene sus acciones y las ejecuta). \"\"\"\n",
    "        if not self.is_done():\n",
    "            actions = []\n",
    "            for agent in self.agents:\n",
    "                if agent.alive:\n",
    "                    actions.append(agent.program(self.percept(agent)))\n",
    "                else:\n",
    "                    actions.append(\"\")\n",
    "            for (agent, action) in zip(self.agents, actions):\n",
    "                self.execute_action(agent, action)\n",
    "\n",
    "    def run(self, steps=1000):\n",
    "        \"\"\"Ejecuta steps pasos en el entorno.\"\"\"\n",
    "        for step in range(steps):\n",
    "            if self.is_done():\n",
    "                return\n",
    "            self.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y7olSAZHnQav"
   },
   "source": [
    "#### Clase <b>VacuumEnvironment</b>\n",
    "\n",
    "Esta clase implementa el entorno del aspirador de 6 posiciones: loc_A, loc_B, loc_C, loc_D, loc_E y loc_F. Cada una de estas posiciones puede tener el estado 'Dirty' o 'Clean'. Un agente en este entorno percibe su localizacion y el estado de la misma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "SMLJe3lPnRW8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Considere el siguiente ambiente:\n",
    "\n",
    "#############\n",
    "# A # B # C #\n",
    "#############\n",
    "# D # E # F #\n",
    "#############\n",
    "# Complete las posiciones reemplazando los guiones bajos por números\n",
    "loc_A, loc_B, loc_C, loc_D, loc_E, loc_F = (0,0), (0,1), (0, 2), (1,0), (1,1), (1,2)\n",
    "\n",
    "class VacuumEnvironment(Environment):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.status = {loc_A: random.choice(['Clean', 'Dirty']),\n",
    "                       loc_B: random.choice(['Clean', 'Dirty']),\n",
    "                       loc_C: random.choice(['Clean', 'Dirty']),\n",
    "                       loc_D: random.choice(['Clean', 'Dirty']),\n",
    "                       loc_E: random.choice(['Clean', 'Dirty']),\n",
    "                       loc_F: random.choice(['Clean', 'Dirty']),}\n",
    "\n",
    "    def thing_classes(self):\n",
    "        return [ReflexVacuumAgent]\n",
    "\n",
    "    def percept(self, agent):\n",
    "        \"\"\"Retorna la posición del agente y el estado de la posición (Dirty/Clean).\"\"\"\n",
    "        return (agent.location, self.status[agent.location])\n",
    "\n",
    "    def execute_action(self, agent, action):\n",
    "        \"\"\"Implementa el MAPA DE TRANSICIÓN: Cambia la posición del agente y/o el estado de la posición; \n",
    "        Cada aspiración (acción 'suck') en una localización Dirty provoca un aumento de desempeño en 10 unidades;\n",
    "        Cada movida efectiva Right, Left, Up o Down provoca una disminución de desempeño en 1 unidad \"\"\"\n",
    "        \n",
    "        if action == 'Suck':\n",
    "            self.status[agent.location] = 'Clean'\n",
    "            agent.performance += 10\n",
    "        else:\n",
    "            # Completar los movimientos para el agente\n",
    "            # Debes identificar la direccion de la accion y modificar acordemente el x o y\n",
    "            # Pista: Ten cuidado con los limites del ambiente!\n",
    "            actual_x, actual_y = agent.location\n",
    "            # Complete su codigo aqui\n",
    "            if action=='Left':\n",
    "                if agent.location==loc_B or agent.location==loc_C or agent.location==loc_E or agent.location==loc_F:\n",
    "                    actual_y-=1\n",
    "            elif action=='Right':\n",
    "                if agent.location==loc_A or agent.location==loc_B or agent.location==loc_D or agent.location==loc_E:\n",
    "                    actual_y+=1\n",
    "            if action=='Up':\n",
    "                if agent.location==loc_D or agent.location==loc_F or agent.location==loc_E:\n",
    "                    actual_x-=1\n",
    "            elif action=='Down':\n",
    "                if agent.location==loc_C or agent.location==loc_A or agent.location==loc_B:\n",
    "                    actual_x+=1 \n",
    "            \n",
    "            \n",
    "            agent.location = actual_x, actual_y\n",
    "            agent.performance -= 1\n",
    "\n",
    "    def default_location(self, thing):\n",
    "        \"\"\"Devuelve una posicion aleatoria.\"\"\"\n",
    "        return random.choice([loc_A, loc_B, loc_C, loc_D])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ETaNXGAoRDs"
   },
   "source": [
    "# Agente Aspirador de 6 posiciones con Programa Reactivo Simple\n",
    "\n",
    "Este agente es el agente aspirador de cuatro posiciones que usa un programa reactivo simple: realiza una accion basado en la percepción (posicion, estado) actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "9pZHxLr3oSg_"
   },
   "outputs": [],
   "source": [
    "def ReflexVacuumAgent():\n",
    "    \n",
    "    def program(percept):\n",
    "        location, status = percept\n",
    "        if status == 'Dirty':\n",
    "            return 'Suck'\n",
    "        elif location == loc_A:\n",
    "            return 'Right'\n",
    "        elif location == loc_B:\n",
    "            return 'Right'\n",
    "        elif location == loc_C:\n",
    "            return 'Down'\n",
    "        elif location == loc_D:\n",
    "            return 'Up'\n",
    "        elif location == loc_E:\n",
    "            return 'Left'\n",
    "        elif location == loc_F:\n",
    "            return 'Left'\n",
    "    return Agent(program)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gV90QCzWpFeB"
   },
   "source": [
    "# Probando el agente reflexivo simple en su entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "B8_JDnAapG-U"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estado Inicial del Ambiente: {(0, 0): 'Clean', (0, 1): 'Dirty', (0, 2): 'Clean', (1, 0): 'Dirty', (1, 1): 'Clean', (1, 2): 'Clean'}\n",
      "ReflexVacuumAgent esta localizado en (0, 0) con desempeño = 0\n",
      "Estado del Ambiente despues de 6 pasos: {(0, 0): 'Clean', (0, 1): 'Clean', (0, 2): 'Clean', (1, 0): 'Dirty', (1, 1): 'Clean', (1, 2): 'Clean'}\n",
      "ReflexVacuumAgent esta localizado en (1, 0) con desempeño = 5\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Crea el entorno del aspirador de 6 posiciones con 2 posiciones en estado 'Dirty'\"\"\"\n",
    "e = VacuumEnvironment()\n",
    "e.status = {loc_A: 'Clean',  loc_B: 'Dirty', loc_C: 'Clean', loc_D: 'Dirty', loc_E: 'Clean', loc_F: 'Clean'}\n",
    "\n",
    "\"\"\"Crea un agente reflexivo simple\"\"\"\n",
    "a = ReflexVacuumAgent()\n",
    "\n",
    "\"\"\"Añade el agente creado al entorno en posicion loc_A\"\"\"\n",
    "e.add_thing(a, location=loc_A) \n",
    "\n",
    "# Imprime el estado inicial del ambiente y localizacion del agente\n",
    "print(\"Estado Inicial del Ambiente: {}\".format(e.status))\n",
    "print(\"ReflexVacuumAgent esta localizado en {} con desempeño = {}\".format(a.location, a.performance))\n",
    "\n",
    "\"\"\"Ejecuta el entorno 6 pasos y obtiene el desempeño del agente\"\"\"\n",
    "e.run(6)\n",
    "\n",
    "# Imprime el estado actual del ambiente, localizacion del agente y su desempeño\n",
    "print(\"Estado del Ambiente despues de 6 pasos: {}\".format(e.status))\n",
    "print(\"ReflexVacuumAgent esta localizado en {} con desempeño = {}\".format(a.location, a.performance))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qdva6vJNpLFq"
   },
   "source": [
    "# Preguntas:\n",
    "1. Completar el codigo en la clase Vacuum Enviroment. No cambiar la medida de desempeño que tiene el ambiente, sólo completar la lógica de movimientos. (**4 pts**)\n",
    "2. Después de haber completado el código, ¿puede plantear un programa de Agente que maximice de mejor manera  la medida de desempeño implementada en el entorno?  No es necesario modificar el código, sino que puede explicarlo en sus propias palabras. (4 pts) (**4 pts**)\n",
    "3. Basado en el programa de agente original, ¿que debería cambiar en el entorno para que el programa de agente maximize la medida de desempeño? Modifique el código. (**4 pts**)\n",
    "4. Según el entorno, ¿existe la posibilidad de que el agente obtenga un desempeño sea negativo? En caso de que su respuesta sea positiva, explique como sería dicho escenario. (**4 pts**)\n",
    "5. ¿Qué característica tendria que tener el entorno para necesitar un agente reactivo basado en modelo? (**4 pts**) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pregunta 1: Codigo completado en la clase Vacuum Enviroment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pregunta 2: \n",
    "# La unica forma en la cual aumenta la medida de desempeño es aspirar basura dado que suma +10 en caso lo haga, es por ello\n",
    "# que en esta parte no se necesitaran los movimientos que realice la aspiradora, solo se necesita retornar suck siempre. \n",
    "# En la funcion program solo se tendria que hacer un action='Suck' y retornarla. AL hacer esto la aspiradora siempre\n",
    "# estará limpiando sin importar si el estado es 'Dirty' o 'Clean' entonces se estaría maximizando su desempeño dado que siempre\n",
    "# estará sumando 10. \n",
    "# Ejem: Para un caso de e.run(6) o en otras palabras 6 pasos la aspiradora presentaría un desempeño de 60."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pregunta 3:\n",
    "#Cambiaria la funcion execute_action de VacuumEnvironment para que maximice la medida de desempeño pero \n",
    "#de forma que solo aspire cuando el espacio esta sucio. De esta forma conseguimos premiar la suciedad \n",
    "#efectiva.\n",
    "#CODIGO:\n",
    "\n",
    "#EL CAMBIO SE REALIZO EN LA LINEA 6 donde agregamos que la condicion de aspirar solo cuando la ubicacion del agente\n",
    "#este sucia.\n",
    "\n",
    "#1 def execute_action(self, agent, action):\n",
    "#2         \"\"\"Implementa el MAPA DE TRANSICIÓN: Cambia la posición del agente y/o el estado de la posición; \n",
    "#3         Cada aspiración (acción 'suck') en una localización Dirty provoca un aumento de desempeño en 10 unidades;\n",
    "#4         Cada movida efectiva Right, Left, Up o Down provoca una disminución de desempeño en 1 unidad \"\"\"\n",
    "#5         \n",
    "#6         if action == 'Suck' and self.status[agent.location]=='Dirty':\n",
    "#7             self.status[agent.location] = 'Clean'\n",
    "#8             agent.performance += 10\n",
    "#9         else:\n",
    "#10            # Completar los movimientos para el agente\n",
    "#11            # Debes identificar la direccion de la accion y modificar acordemente el x o y\n",
    "#12            # Pista: Ten cuidado con los limites del ambiente!\n",
    "#13           actual_x, actual_y = agent.location\n",
    "#14            # Complete su codigo aqui\n",
    "#15            if action=='Left':\n",
    "#16                if agent.location==loc_B or agent.location==loc_C or agent.location==loc_E or agent.location==loc_F:\n",
    "#17                    actual_y-=1\n",
    "#18            elif action=='Right':\n",
    "#19                if agent.location==loc_A or agent.location==loc_B or agent.location==loc_D or agent.location==loc_E:\n",
    "#20                    actual_y+=1\n",
    "#21            if action=='Up':\n",
    "#22                if agent.location==loc_D or agent.location==loc_F:\n",
    "#23                    actual_x-=1\n",
    "#24            elif action=='Down':\n",
    "#25                if agent.location==loc_C or agent.location==loc_A:\n",
    "#26                    actual_x+=1          \n",
    "#27            agent.location = actual_x, actual_y\n",
    "#28            agent.performance -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pregunta 4:\n",
    "# Un desempeño negativo se puede dar por dos factores: la cantidad de suciedad en el ambiente y el numero de pasos digitado\n",
    "# por el usuario que dará el agente.\n",
    "\n",
    "# CASO 1:\n",
    "# No existe suciedad en el ambiente y el numero de pasos es mayor a cero\n",
    "\n",
    "# CASO 2:\n",
    "# Existe suciedad en el ambiente pero el numero de pasos es menor que el necesario para encontrar la primera suciedad\n",
    "# Ejemplo: Numero de pasos:4 C-->CLEAN   D-->DIRTY\n",
    "# A(C) -> B(C) -> C(C)\n",
    "# |                 | \n",
    "# D(D) <- E(C) <- F(C)\n",
    "# En este caso no encontramos suciedad alguna por lo tanto la medida de desempeño sera negativa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pregunta 5:\n",
    "# La diferente entre el reactivo basado en modelo y el reactivo simple es que en el de modelo el estado es una \n",
    "# variable interna que la modela el agente. El agente no confia mucho en la percepcion actual sino que tiene un estado\n",
    "# interno el cual actualiza cuando recibe una percepcion pero no solo basado en esta sino en el modelo del mundo.\n",
    "# La caracteristica ideal para usar esta estructura de agente es que el entorno sea parcialmente observable ya que \n",
    "# como lo mencioné anteriormente, el modelo se presta para trabajar en estos entornos."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Laboratorio1_2021-1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
